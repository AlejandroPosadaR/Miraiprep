spring.application.name=aimock

# Spring AI OpenAI Configuration
spring.ai.openai.api-key=${SPRING_AI_OPENAI_API_KEY}
spring.ai.openai.chat.options.model=gpt-4o-mini
spring.ai.openai.chat.options.temperature=0.8
# OpenAI HTTP Client Configuration (optimized for low latency)
# Connection timeout: how long to wait to establish connection
spring.ai.openai.client.connection-timeout=10s
# Read timeout: how long to wait for response data
spring.ai.openai.client.read-timeout=60s
# Connection pool: reuse connections for faster subsequent requests
# Increased from 5 to 15 to reduce connection overhead for concurrent requests
spring.ai.openai.client.connection-pool.max-idle=15
spring.ai.openai.client.connection-pool.max-idle-time=60s
# Base URL (optional, for custom endpoints or proxies)
# spring.ai.openai.base-url=https://api.openai.com/v1

# AWS RDS PostgreSQL Configuration
# Get these values from: AWS Console → RDS → Your Database Instance
# Connection string format: jdbc:postgresql://your-db.region.rds.amazonaws.com:5432/yourdb
spring.datasource.url=${DATABASE_URL}
spring.datasource.username=${DATABASE_USERNAME:postgres}
# Password: Provide DATABASE_PASSWORD in environment variables
spring.datasource.password=${DATABASE_PASSWORD}
spring.datasource.driver-class-name=org.postgresql.Driver

# SSL Configuration
# SSL is configured via JDBC URL parameter: sslmode=require
# Do NOT set HikariCP SSL properties as they conflict with URL parameters

# HikariCP Connection Pool (optimized for RDS)
# Reduced timeout for faster failure feedback during development
spring.datasource.hikari.connection-timeout=10000
spring.datasource.hikari.initialization-fail-timeout=10000
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.minimum-idle=2
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.max-lifetime=600000
# Connection test query for RDS
spring.datasource.hikari.connection-test-query=SELECT 1

# JPA/Hibernate
spring.jpa.hibernate.ddl-auto=validate
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.show-sql=false
# Delay JPA initialization until datasource is ready
spring.jpa.properties.hibernate.temp.use_jdbc_metadata_defaults=false

# Flyway (uses same connection as datasource)
spring.flyway.enabled=true
spring.flyway.baseline-on-migrate=true
spring.flyway.validate-on-migrate=true
# Ensure Flyway uses the same connection settings
spring.flyway.url=${spring.datasource.url}
spring.flyway.user=${spring.datasource.username}
spring.flyway.password=${spring.datasource.password}

# JWT Configuration
jwt.secret=5367566859703373367639792F423F452848284D6251655468576D5A71347437
jwt.expiration=86400000

# Server
server.port=8080

# Multipart file upload configuration (for audio transcription)
spring.servlet.multipart.enabled=true
spring.servlet.multipart.max-file-size=25MB
spring.servlet.multipart.max-request-size=25MB

# CORS
app.cors.allowed-origins=http://localhost:5173,http://localhost:3000

# Logging
logging.level.org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer=ERROR

# AI Processing Configuration
# SQS is disabled by default. To enable:
# 1. Set SQS_QUEUE_URL environment variable
# 2. Set APP_SQS_ENABLED=true environment variable
app.sqs.enabled=${APP_SQS_ENABLED:false}
app.sqs.queue-url=${SQS_QUEUE_URL:}
# Polling configuration (for low latency)
app.sqs.poll-interval-ms=100
app.sqs.wait-time-seconds=20
app.sqs.max-messages=10

# TTS Provider Configuration
tts.provider=${TTS_PROVIDER:openai}
elevenlabs.api-key=${ELEVENLABS_API_KEY:}

# Actuator / Prometheus Configuration
management.endpoints.web.exposure.include=health,info,prometheus,metrics
management.endpoint.health.show-details=when-authorized
management.endpoint.health.probes.enabled=true
management.health.livenessState.enabled=true
management.health.readinessState.enabled=true
management.metrics.export.prometheus.enabled=true
management.metrics.tags.application=${spring.application.name}
management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.metrics.distribution.percentiles.http.server.requests=0.5,0.75,0.95,0.99
management.metrics.distribution.percentiles-histogram.ai.response.duration=true
management.metrics.distribution.percentiles.ai.response.duration=0.5,0.75,0.95,0.99
management.metrics.distribution.percentiles-histogram.ai.time_to_first_token=true
management.metrics.distribution.percentiles.ai.time_to_first_token=0.5,0.75,0.95,0.99
